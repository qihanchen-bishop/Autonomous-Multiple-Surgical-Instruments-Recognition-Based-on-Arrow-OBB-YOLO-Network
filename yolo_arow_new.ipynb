{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于colab加载google drive文件\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# os.chdir(\"/content/drive/MyDrive/arrow_run/yolov3_arrow_run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63FXCgL1FVD6"
   },
   "source": [
    "# 1 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ4h8-G0FVD-"
   },
   "source": [
    "## 1.1 画出包围盒，同时生成txt文件\n",
    "方便标注箭头，因为我们这里采用的是先标注包围盒，再标注箭头\n",
    "所以要根据标注文件先生成有包围盒的图片，在进行标注，同时生成包围盒对应的txt文件，可以作为原训练的数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdQtJT8zFVD_"
   },
   "outputs": [],
   "source": [
    "# 导入库文件\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh7Fze8FFVEA"
   },
   "outputs": [],
   "source": [
    "# 生成需要的路径\n",
    "if not os.path.exists('data/ImgWithBB/'): # 带包围盒的图片\n",
    "    os.makedirs('data/ImgWithBB/') \n",
    "if not os.path.exists('data/ImgWithBBA/'): # 带箭头包围盒的图片\n",
    "    os.makedirs('data/ImgWithBBA/') \n",
    "if not os.path.exists('data/labels_b/'): # 只有包围盒的标签文件\n",
    "    os.makedirs('data/labels_b/') \n",
    "if not os.path.exists('data/labels_a/'): # 带有箭头包围盒的标签文件\n",
    "    os.makedirs('data/labels_a/') \n",
    "if not os.path.exists('data/ImageSets'): # 放置划分之后的数据集\n",
    "    os.makedirs('data/ImageSets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peO9vYrcFVEA"
   },
   "outputs": [],
   "source": [
    "wd = getcwd() # 获取当前路径\n",
    "data_path = wd+\"/data/\"\n",
    "classes = []#对应的类别\n",
    "\n",
    "# 获取类别，打开之后记得关闭\n",
    "class_list_file = open(data_path+'class_list.txt') \n",
    "for i in class_list_file.readlines():\n",
    "  # print(i[2:-1])\n",
    "  classes.append(i[2:-1]) \n",
    "class_list_file.close() # 记得关闭文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数定义\n",
    "def convert_box(size, box):\n",
    "    # 根据xml文件，输出归一化的包围盒数据\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    # 获取包围盒中心的坐标\n",
    "    x = (box[0] + box[1]) / 2.0\n",
    "    y = (box[2] + box[3]) / 2.0\n",
    "    # 获取包围盒的宽和高\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    # 转换成0，1之间的数字\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "\n",
    "    for i in [x,y,w,h]:\n",
    "        if i < 0 or i > 1:\n",
    "            return False\n",
    "    # 转换成包围盒中心坐标盒长宽，已经归一化处理\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def draw_bb(image_id):\n",
    "    # 根据id读取图片盒对应的xml文件，生成包围盒图片和txt文件，返回错误的数据\n",
    "    img_path = data_path+'JPEGImages/%s.jpg'%(image_id)\n",
    "    out_path = data_path+'ImgWithBB/%s_BB.jpg' % (image_id)\n",
    "    out_txt_path = data_path+'labels_b/%s.txt' % (image_id)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    # 打开txt文件\n",
    "    out_txt = open(out_txt_path,'w')\n",
    "    # 读取xml文件\n",
    "    xml_file = open('data/Annotations/%s.xml' % (image_id))\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    # 获取长宽\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    # 有不要的标签，错误的标记\n",
    "    noneedlbox = \"no\"\n",
    "    errorlabel = \"no\"\n",
    "    \n",
    "    for i,obj in enumerate(root.iter('object')):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls_ = obj.find('name').text\n",
    "\n",
    "        if cls_ not in classes or int(difficult) == 1:\n",
    "            noneedlbox = image_id\n",
    "            continue\n",
    "        \n",
    "        cls_id = classes.index(cls_)\n",
    "        # 获取文字区域框大小\n",
    "        t_size = cv2.getTextSize('%d_%s'%(i,cls_), 1, cv2.FONT_HERSHEY_PLAIN, 1)[0]\n",
    "\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        # 获取像素坐标\n",
    "        b = [int(xmlbox.find('xmin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymin').text),\n",
    "                int(xmlbox.find('ymax').text)]\n",
    "        # 写入txt\n",
    "        bb = convert_box((w, h), b)\n",
    "\n",
    "        if bb == False:\n",
    "            errorlabel = image_id\n",
    "            continue\n",
    "        out_txt.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "        # 获取 文字区域右下角坐标\n",
    "        ptLeftTop = np.array([b[0],b[2]])\n",
    "        textlbottom = ptLeftTop - np.array(list(t_size))\n",
    "        # print(ptLeftTop,textlbottom,t_size)\n",
    "        # 绘制文字区域矩形框\n",
    "        # cv2.rectangle(img, tuple(ptLeftTop), tuple(textlbottom),  (0, 100, 0), -1)\n",
    "        # 计算文字起始位置偏移\n",
    "        ptLeftTop[1] = ptLeftTop[1] - t_size[1]/2\n",
    "        if ptLeftTop[1] < t_size[1]:\n",
    "            ptLeftTop[1] = ptLeftTop[1] + 2*t_size[1] + b[3] - b[2]\n",
    "        # 绘字\n",
    "        cv2.putText(img, '%d_%s'%(i,cls_) , tuple(ptLeftTop), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), 1)\n",
    "        # 绘图\n",
    "        cv2.rectangle(img, (b[0],b[2]), (b[1],b[3]), (0,255,0), 2)\n",
    "    \n",
    "    out_txt.close()\n",
    "    xml_file.close()\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "    return noneedlbox,errorlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaJbsAVEFVEB"
   },
   "outputs": [],
   "source": [
    "label_path = 'data/Annotations'\n",
    "total_label = os.listdir(label_path)\n",
    "n_list = []\n",
    "e_list = []\n",
    "for i in total_label:\n",
    "    noneedlabel,errorlabel = draw_bb(i[:-4])\n",
    "    if noneedlabel != 'no':\n",
    "        n_list.append(noneedlabel)\n",
    "    if errorlabel != \"no\":\n",
    "        e_list.append(errorlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTBb2Xj1FVEC",
    "outputId": "5e8c4493-dac9-441e-97c7-5f21683dfcfa"
   },
   "outputs": [],
   "source": [
    "print(\"total:%d,noneedlabels:%d,errorlabel:%d\"%(len(total_label),len(n_list),len(e_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pE2PbUhFVEC"
   },
   "outputs": [],
   "source": [
    "# 记录有袋子列表\n",
    "n_file = open('data/bag_list.txt','w')\n",
    "for i in n_list:\n",
    "    n_file.write(i+'\\n')\n",
    "n_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUdLqiSUFVED"
   },
   "source": [
    "## 1.2 读取箭头txt，与xml一起生成labels_a两个文件夹的txt，同时生成带箭头包围盒的图片\n",
    "bag不画，不写入txt，只是记录下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4SGxH9BFVED"
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "import cv2\n",
    "from os import listdir, getcwd\n",
    "import numpy as np\n",
    "wd = getcwd()\n",
    "data_path = wd+\"/data/\"\n",
    "\n",
    "classes = []#对应的类别\n",
    "class_list_file = open(data_path+'class_list.txt') \n",
    "for i in class_list_file.readlines():\n",
    "  # print(i[2:-1])\n",
    "  classes.append(i[2:-1]) \n",
    "\n",
    "def convert_box_with_arrow(size, box, arrow):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    # 获取包围盒中心的坐标\n",
    "    x = (box[0] + box[1]) / 2.0\n",
    "    y = (box[2] + box[3]) / 2.0\n",
    "    # 获取包围盒的宽和高\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    # 箭头坐标转换,相对于包围盒左上角的坐标，并且归一到0，1之间\n",
    "    ax1 = (arrow[0][0] - box[0]) / w\n",
    "    ax2 = (arrow[1][0] - box[0]) / w\n",
    "    ay1 = (arrow[0][1] - box[2]) / h\n",
    "    ay2 = (arrow[1][1] - box[2]) / h\n",
    "    # 转换成0，1之间的数字\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "\n",
    "    for i in [x,y,w,h,ax1,ax2,ay1,ay2]:\n",
    "        if i < 0 or i > 1:\n",
    "            return False\n",
    "    # 转换成包围盒中心坐标盒长宽，已经归一化处理\n",
    "    return (x, y, w, h, ax1, ay1, ax2, ay2)\n",
    "\n",
    "def draw_arrow(image_id):\n",
    "    # 读取图片\n",
    "    img_path = data_path+'JPEGImages/%s.jpg'%(image_id)\n",
    "    out_path = 'data/ImgWithBBA/%s_BBA.jpg' % (image_id)\n",
    "    out_file_a = open('data/labels_a/%s.txt' % (image_id), 'w')\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # 读取xml文件\n",
    "    xml_file = open('data/Annotations/%s.xml' % (image_id))\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    # 获取长宽\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "    # 读取箭头文件\n",
    "    arrow_file = open('data/Arrow/%s_BB.txt' % (image_id))\n",
    "    arrow_points = []\n",
    "    # 有不要的标签，错误的标记\n",
    "    noneedlbox = \"no\"\n",
    "    errorlabel = \"no\"\n",
    "\n",
    "    for i,line in enumerate(arrow_file.readlines()):\n",
    "        if i != 0:\n",
    "            point = line[:-1].split(' ')\n",
    "            arrow_points.append([int(w*float(point[0])),int(h*float(point[1]))])\n",
    "    \n",
    "    a_i = 0\n",
    "    for i,obj in enumerate(root.iter('object')):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls_ = obj.find('name').text\n",
    "\n",
    "        if cls_ not in classes or int(difficult) == 1:\n",
    "            noneedlbox = image_id\n",
    "            continue\n",
    "        \n",
    "        cls_id = classes.index(cls_)\n",
    "        # 获取文字区域框大小\n",
    "        t_size = cv2.getTextSize('%d_%s'%(i,cls_), 1, cv2.FONT_HERSHEY_PLAIN, 1)[0]\n",
    "\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        # 获取像素坐标\n",
    "        b = [int(xmlbox.find('xmin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymin').text),\n",
    "                int(xmlbox.find('ymax').text)]\n",
    "        # 写入txt\n",
    "        bb_a = convert_box_with_arrow((w, h), b,(arrow_points[2*a_i],arrow_points[2*a_i+1]))\n",
    "        \n",
    "        if bb_a == False:\n",
    "            errorlabel = image_id\n",
    "            continue\n",
    "\n",
    "        bb = bb_a[:4]\n",
    "\n",
    "        # 写进txt\n",
    "        # out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "        out_file_a.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb_a]) + '\\n')\n",
    "        # 获取 文字区域右下角坐标\n",
    "        ptLeftTop = np.array([b[0],b[2]])\n",
    "        textlbottom = ptLeftTop - np.array(list(t_size))\n",
    "        # print(ptLeftTop,textlbottom,t_size)\n",
    "        # 绘制文字区域矩形框\n",
    "        # cv2.rectangle(img, tuple(ptLeftTop), tuple(textlbottom),  (0, 100, 0), -1)\n",
    "        # 计算文字起始位置偏移\n",
    "        ptLeftTop[1] = ptLeftTop[1] - t_size[1]/2\n",
    "        if ptLeftTop[1] < t_size[1]:\n",
    "            ptLeftTop[1] = ptLeftTop[1] + 2*t_size[1] + b[3] - b[2]\n",
    "        # 绘字\n",
    "        cv2.putText(img, '%d_%s'%(i,cls_) , tuple(ptLeftTop), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), 1)\n",
    "        # 绘图\n",
    "        cv2.rectangle(img, (b[0],b[2]), (b[1],b[3]), (0,255,0), 2)\n",
    "        cv2.arrowedLine(img,(arrow_points[2*a_i][0],arrow_points[2*a_i][1]), (arrow_points[2*a_i+1][0],arrow_points[2*a_i+1][1]), (0,0,255),2,0,0,0.2)\n",
    "        cv2.circle(img,(arrow_points[2*a_i][0],arrow_points[2*a_i][1]),1,(0,225,225),4)\n",
    "        cv2.circle(img,(arrow_points[2*a_i+1][0],arrow_points[2*a_i+1][1]), 1, (0,225,225),4)\n",
    "        a_i += 1\n",
    "\n",
    "    cv2.imwrite(out_path, img)\n",
    "    arrow_file.close()\n",
    "    out_file_a.close()\n",
    "    xml_file.close()\n",
    "    return noneedlbox,errorlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-pkjF_CFVEH",
    "outputId": "37a0620d-6e4a-4755-8d5f-bf551711f5d5"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data/ImgWithBBA/'):\n",
    "    os.makedirs('data/ImgWithBBA/')  \n",
    "if not os.path.exists('data/labels/'):\n",
    "    os.makedirs('data/labels/') \n",
    "if not os.path.exists('data/labels_a/'):\n",
    "    os.makedirs('data/labels_a/') \n",
    "n,e = draw_arrow('v01_026925')\n",
    "print(n,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZgOmx2XFVEI",
    "outputId": "aea755f1-3317-48c7-d8de-6b08b9ca9a90"
   },
   "outputs": [],
   "source": [
    "# 将全部xml转换成txt，同时去掉bag的标签\n",
    "arrowpath = 'data/Arrow'\n",
    "total_arrow = os.listdir(arrowpath)\n",
    "n_list = []\n",
    "e_list = []\n",
    "for i in total_arrow:\n",
    "    noneedlabel,errorlabel = draw_arrow(i[:-7])\n",
    "    if noneedlabel != 'no':\n",
    "        n_list.append(noneedlabel)\n",
    "    if errorlabel != \"no\":\n",
    "        e_list.append(errorlabel)\n",
    "print(\"total:%d,noneedlabels:%d,errorlabel:%d\"%(len(total_arrow),len(n_list),len(e_list)))\n",
    "# 2810 - 3 = 2807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqUmzJ3UFVEI"
   },
   "outputs": [],
   "source": [
    "# 记录错误列表\n",
    "e_file = open('data/e_list.txt','w')\n",
    "for i in e_list:\n",
    "    e_file.write(i+'\\n')\n",
    "e_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41VldOQtFVEJ"
   },
   "source": [
    "## 1.3 数据划分\n",
    "在数据划分之前先尝试能否成labels画出这个图,记得转成整数\n",
    "根据需要设置划分比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uqNJVtfiFVEJ",
    "outputId": "92d8a157-cb0d-41cb-c172-8beeaaddbda1"
   },
   "outputs": [],
   "source": [
    "# 从label反画图\n",
    "labela = open('data/labels_a/v01_002075.txt')\n",
    "img = cv2.imread('data/JPEGImages/v01_002075.jpg')\n",
    "imgh = img.shape[0]\n",
    "imgw = img.shape[1]\n",
    "print(imgw,imgh)\n",
    "for (index,i) in enumerate(labela.readlines()):\n",
    "    pl = i.strip().split(' ')\n",
    "    rl = [float(a) for a in pl] # cls_ x y w h ax1 ay1 ax2 ay2\n",
    "    print(rl)\n",
    "    cls_ = classes[int(rl[0])]\n",
    "    print(cls_)\n",
    "    x = int(rl[1]*imgw)\n",
    "    y = int(rl[2]*imgh)\n",
    "    w = int(rl[3]*imgw)\n",
    "    h = int(rl[4]*imgh)\n",
    "    lefttopx = int(x - w/2)\n",
    "    rightbottomx = int(x + w/2)\n",
    "    lefttopy = int(y - h/2)\n",
    "    rightbottomy = int(y + h/2)\n",
    "    ax1 = int(rl[5]*w + lefttopx)\n",
    "    ay1 = int(rl[6]*h + lefttopy)\n",
    "    ax2 = int(rl[7]*w + lefttopx)\n",
    "    ay2 = int(rl[8]*h + lefttopy)\n",
    "    # 绘字\n",
    "    # 获取文字区域框大小\n",
    "    t_size = cv2.getTextSize('%d_%s'%(index,cls_), 1, cv2.FONT_HERSHEY_PLAIN, 1)[0]\n",
    "    ptLeftTop = np.array([lefttopx,lefttopy])\n",
    "    textlbottom = ptLeftTop - np.array(list(t_size))\n",
    "\n",
    "    # 计算文字起始位置偏移\n",
    "    ptLeftTop[1] = ptLeftTop[1] - t_size[1]/2\n",
    "    if ptLeftTop[1] < t_size[1]:\n",
    "        ptLeftTop[1] = ptLeftTop[1] + 2*t_size[1] + h\n",
    "    cv2.putText(img, '%d_%s'%(index,cls_) , tuple(ptLeftTop), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), 1)\n",
    "    # 绘图\n",
    "    cv2.rectangle(img, (lefttopx,lefttopy), (rightbottomx,rightbottomy), (0,255,0), 2)\n",
    "    cv2.arrowedLine(img,(ax1,ay1), (ax2,ay2), (0,0,255),2,0,0,0.2)\n",
    "cv2.imshow('img1', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72B8ioRkFVEJ"
   },
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "import os\n",
    "import random\n",
    "\n",
    "testval_percent = 0.2 # 0.2的数据用于验证和测试\n",
    "test_percent = 0.5 # 其中一半用在测试\n",
    "filepath = 'data/labels_b'\n",
    "txtsavepath = 'data/ImageSets'\n",
    "total = os.listdir(filepath)\n",
    "\n",
    "num = len(total)  #统计所有的标注文件\n",
    "filelist = range(num)     \n",
    "tv = int(num * testval_percent)  # 设置测试验证集的数目\n",
    "tr = int(tv * test_percent)      # 设置测试集的数目\n",
    "testval = random.sample(filelist, tv)\n",
    "test = random.sample(testval, tr)\n",
    "\n",
    "# txt 文件写入的只是xml 文件的文件名（数字），没有后缀，如下图。\n",
    "ftestval = open('data/ImageSets/testval.txt', 'w')\n",
    "ftest = open('data/ImageSets/test.txt', 'w')\n",
    "ftrain = open('data/ImageSets/train.txt', 'w')\n",
    "fval = open('data/ImageSets/val.txt', 'w')\n",
    "\n",
    "for i in filelist:\n",
    "    name = total[i][:-4] + '\\n'\n",
    "    if i in testval:\n",
    "        ftestval.write(name)\n",
    "        if i in test:\n",
    "            ftest.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftrain.write(name)\n",
    "\n",
    "ftestval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RUdeitxFVEK"
   },
   "outputs": [],
   "source": [
    "# 在data下面把图片路径写入对应的txt\n",
    "sets = ['train', 'test', 'val']\n",
    "for image_set in sets:\n",
    "    image_ids = open('data/ImageSets/%s.txt' % (image_set)).read().strip().split()\n",
    "    list_file = open('data/%s.txt' % (image_set), 'w')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write('data/JPEGImages/%s.jpg\\n' % (image_id))\n",
    "    list_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD_WJ0jLHvTn"
   },
   "source": [
    "# 2 选出锚盒\n",
    "因为我们需要根据自己的数据选择预设锚盒，运行下面代码后，将输出写入cfg文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzf36Jm1Hr1Q"
   },
   "outputs": [],
   "source": [
    "from utils.utils import *; \n",
    "k = kmean_anchors('data/train.txt',n=9,gen=10000)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "88,59, 103,84, 136,71, 135,102, 177,89, 153,132, 189,111, 215,141, 276,190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3MoheXAFVEK"
   },
   "source": [
    "# 3 尝试完整的将yolov3.tiny跑起来\n",
    "修改cfg文件\n",
    "\n",
    "修改yolo.data yolo.names\n",
    "\n",
    "将dataset.py 295行的labels改成labels_a，336行label初始化成9个，364行，每一行的个数改成9个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hSAgisjmzIR"
   },
   "outputs": [],
   "source": [
    "from utils.utils import *; \n",
    "k = kmean_anchors('data/train.txt',n=6,gen=5000)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3A74wSyFVEL",
    "outputId": "8b2e7a7d-6c54-426c-834d-f2db2e4f5797"
   },
   "outputs": [],
   "source": [
    "95，61， 118，84， 172，90， 138，115， 183，127， 252，156\n",
    "# yolo 层的输出 X,y,w,h,置信度，箭头坐标(x1,y1,x2,y2),类别概率6个\n",
    "# 所以前一层的卷积层大小为\n",
    "print(3 * (4 + 1 + 4 + 6))\n",
    "# 然后yolo层的类别改成6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3590065,
     "status": "ok",
     "timestamp": 1631779801942,
     "user": {
      "displayName": "四婆",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423429648315720365"
     },
     "user_tz": -480
    },
    "id": "AUgcd41JFVEL",
    "outputId": "9a01cf94-2eb0-43b3-98d6-79963aead25c"
   },
   "outputs": [],
   "source": [
    "!python train.py --data data/yolo.data --cfg cfg/yolov3-tiny-my.cfg --device 0 --weights weights/yolov3-tiny.weights --epochs 30 --batch 16 --phased\n",
    "# v01_054600 箭头标到了边界，右出结果大于1\n",
    "# 忘了训练多少epoch，关系不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data data/yolo.data --cfg cfg/yolov3-arrow6.cfg --device 0 --weights weights/yolov3.weights --epochs 200 --batch 16 --phased\n",
    "# --phased\n",
    "# v01_054600 箭头标到了边界，右出结果大于1\n",
    "# 忘了训练多少epoch，关系不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --data data/yolo.data --cfg cfg/yolov3-arrow6.cfg --device 0 --weights weights/b6_150_last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYypBerJFVEM"
   },
   "source": [
    "# 5 代码修改尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ggkvtO5FVEM"
   },
   "outputs": [],
   "source": [
    "# 需要对loadlabel函数进行更改\n",
    "    # Dataset\n",
    "dataset = LoadImagesAndLabels(train_path, img_size, batch_size,\n",
    "                                augment=True,\n",
    "                                hyp=hyp,  # augmentation hyperparameters\n",
    "                                rect=opt.rect,  # rectangular training\n",
    "                                cache_images=opt.cache_images,\n",
    "                                single_cls=opt.single_cls)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = min(batch_size, len(dataset))\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=nw,\n",
    "                                            shuffle=not opt.rect,  # Shuffle=True unless rectangular training is used\n",
    "                                            pin_memory=True,\n",
    "                                            collate_fn=dataset.collate_fn)\n",
    "model.train()\n",
    "\n",
    "# Update image weights (optional)\n",
    "if dataset.image_weights:\n",
    "    w = model.class_weights.cpu().numpy() * (1 - maps) ** 2  # class weights\n",
    "    image_weights = labels_to_image_weights(dataset.labels, nc=nc, class_weights=w)\n",
    "    dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # rand weighted idx\n",
    "\n",
    "mloss = torch.zeros(4).to(device)  # mean losses\n",
    "# print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n",
    "# 进度条构建\n",
    "pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n",
    "for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvTIEA_0FVEM"
   },
   "outputs": [],
   "source": [
    "# 一些应该掌握的操作\n",
    "print(torch.cat((a,b),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LD2pLAijFVEM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.onnx\n",
    " \n",
    "import netron\n",
    " \n",
    " \n",
    "class ForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ForwardNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    " \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, bias=False)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, 3, padding=1, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        identity = x\n",
    "        x = F.relu(self.block1(x) + identity)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    " \n",
    " \n",
    "input = torch.rand(1, 3, 416, 416)\n",
    "model = ForwardNet()\n",
    "output = model(input)\n",
    " \n",
    "onnx_path = \"netForwatch.onnx\"\n",
    "torch.onnx.export(model, input, onnx_path)\n",
    " \n",
    "netron.start(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9_9Diy8FVEN"
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "import torch.onnx\n",
    " \n",
    "import netron\n",
    "\n",
    "# Hyperparameters\n",
    "hyp = {'giou': 3.54,  # giou loss gain\n",
    "       'cls': 37.4,  # cls loss gain\n",
    "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
    "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "       'iou_t': 0.20,  # iou training threshold\n",
    "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
    "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
    "       'momentum': 0.937,  # SGD momentum\n",
    "       'weight_decay': 0.0005,  # optimizer weight decay\n",
    "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
    "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
    "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
    "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
    "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
    "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
    "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
    "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
    "nc = 7\n",
    "hyp['cls'] *= nc / 80  # update coco-tuned hyp['cls'] to current dataset\n",
    "# model.train()\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "cfg = 'cfg/yolov3.cfg'\n",
    "model = Darknet(cfg).to(device)\n",
    "\n",
    "model.nc = nc  # attach number of classes to model\n",
    "model.hyp = hyp  # attach hyperparameters to model\n",
    "model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n",
    "\n",
    "model.train()\n",
    "# input = torch.rand(1, 3, 416, 416).to(device)\n",
    "# # model.eval()\n",
    "# output = model(input)\n",
    "# print(len(output))\n",
    "# onnx_path = \"netForwatch.onnx\"\n",
    "# torch.onnx.export(model, input, onnx_path, opset_version=11)\n",
    "# netron.start(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dZUKkv5FVEN"
   },
   "outputs": [],
   "source": [
    "print(output[...,0].shape)#12=7+4+1\n",
    "print(output[1].shape)\n",
    "print(output[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnNfLbK2FVEN",
    "outputId": "b46648ad-3d32-455c-afbf-65575f4e3d5b"
   },
   "outputs": [],
   "source": [
    "# 深度36变成3*12，这一步看看怎么变，我们的目标是7+4+1+2+2=16\n",
    "# 所以深度可能改成48就有可能实现\n",
    "# 36是yolo前一层的输出\n",
    "# \n",
    "input = torch.rand(1, 48, 13, 13)\n",
    "print(input[...,0:2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gO0bZ9IPFVEO"
   },
   "outputs": [],
   "source": [
    "# 接下来看数据加载的target怎么搞的\n",
    "# 训练时的target就是文件写入的格式\n",
    "# 也就是我们是往文件的格式靠近，那test做了一件什么事情呢，关键就在于那几个约束和原先的关系\n",
    "from utils.datasets import *\n",
    "from tqdm import tqdm\n",
    "train_path = \"data/val.txt\"\n",
    "# Hyperparameters\n",
    "hyp = {'giou': 3.54,  # giou loss gain\n",
    "       'cls': 37.4,  # cls loss gain\n",
    "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
    "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "       'iou_t': 0.20,  # iou training threshold\n",
    "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
    "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
    "       'momentum': 0.937,  # SGD momentum\n",
    "       'weight_decay': 0.0005,  # optimizer weight decay\n",
    "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
    "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
    "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
    "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
    "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
    "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
    "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
    "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
    "nc = 7\n",
    "hyp['cls'] *= nc / 80  # update coco-tuned hyp['cls'] to current dataset\n",
    "img_size = 416\n",
    "batch_size = 16\n",
    "rect = False\n",
    "cache_images = False\n",
    "sing = False\n",
    "dataset = LoadImagesAndLabels(train_path, img_size, batch_size,\n",
    "                                augment=True,\n",
    "                                hyp=hyp,  # augmentation hyperparameters\n",
    "                                rect=rect,  # rectangular training\n",
    "                                cache_images=cache_images,\n",
    "                                single_cls=sing)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=4,\n",
    "                                            shuffle=not rect,  # Shuffle=True unless rectangular training is used\n",
    "                                            pin_memory=True,\n",
    "                                            collate_fn=dataset.collate_fn)\n",
    "\n",
    "pbar = tqdm(enumerate(dataloader), total=batch_size)  # progress bar\n",
    "for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
    "    print(targets.shape)\n",
    "    print(type(targets))\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz5Y_3RjFVEO"
   },
   "source": [
    "## 5.2 误差计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBS1nYoHFVEO"
   },
   "outputs": [],
   "source": [
    "# 其实在误差计算里面已经有对这些进行处理了\n",
    "# 目前看下来只要修改输入文件，以及对输入维度的一些判断\n",
    "# cfgyolo前面的维度，其他模型输出目前还不用更改\n",
    "# 误差计算\n",
    "# 箭头坐标点，如果用比例表示，计算误差时，大小尺寸就一样了，实际上需要考虑到包围盒的大小，所以计算误差应该借助实际包围盒的大小\n",
    "\n",
    "# 坐标点：没有约束的坐标点，约束到包围盒里面的坐标点，直接计算误差，结合包围盒实际大小计算误差\n",
    "from utils.utils import *\n",
    "import torch\n",
    "from models import *\n",
    "import torch.onnx\n",
    " \n",
    "# import netron\n",
    "\n",
    "# Hyperparameters\n",
    "hyp = {'giou': 3.54,  # giou loss gain\n",
    "       'cls': 37.4,  # cls loss gain\n",
    "       'arrow':1.0, # 后面可以考虑加一下，对误差比例进行缩放\n",
    "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
    "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "       'iou_t': 0.20,  # iou training threshold\n",
    "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
    "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
    "       'momentum': 0.937,  # SGD momentum\n",
    "       'weight_decay': 0.0005,  # optimizer weight decay\n",
    "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
    "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
    "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
    "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
    "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
    "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
    "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
    "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
    "nc = 7\n",
    "hyp['cls'] *= nc / 80  # update coco-tuned hyp['cls'] to current dataset\n",
    "# model.train()\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "cfg = 'cfg/yolo-my.cfg'\n",
    "model = Darknet(cfg).to(device)\n",
    "\n",
    "model.nc = nc  # attach number of classes to model\n",
    "model.hyp = hyp  # attach hyperparameters to model\n",
    "model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n",
    "\n",
    "tags = torch.tensor([[ 0.00000,  2.00000,  0.19658,  0.20487,  0.26816,  0.15605,0.1,0.2,0.3,0.4],\n",
    "[ 0.00000,  1.00000,  0.78653,  0.36487,  0.14542,  0.15631, 0.1,0.2,0.3,0.4]]).to(device)\n",
    "inp = torch.rand(1, 3, 416, 416).to(device)\n",
    "# model.eval()\n",
    "model.train()\n",
    "output = model(inp)\n",
    "# filter = non_max_suppression(output[0], conf_thres=0.0001, iou_thres=0.6, multi_label=True)\n",
    "# print(filter[0].shape)\n",
    "loss,loss_item = compute_loss(output, tags, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvePHfptFVEO",
    "outputId": "e0677927-25e2-44a7-e3ee-be03a4779e05"
   },
   "outputs": [],
   "source": [
    "print(output[1].shape)\n",
    "i = output[1][...,0]\n",
    "print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5o2DTWaLFVEP",
    "outputId": "469398a4-fce6-4b1a-ab9e-01b3b0c81b10"
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "x = torch.Tensor([-1,2])\n",
    "y = torch.Tensor([0,2])\n",
    "a = torch.atan(x/y)\n",
    "# m.atan(x/y)\n",
    "# m.pi/4\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "error",
     "timestamp": 1631672168524,
     "user": {
      "displayName": "四婆",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423429648315720365"
     },
     "user_tz": -480
    },
    "id": "JAaNO5pGOFo7",
    "outputId": "ea540399-3c52-4d77-a01a-8e10d784ad87"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "hyp = {'giou': 3.54,  # giou loss gain\n",
    "       'cls': 37.4,  # cls loss gain\n",
    "       'arrow':1.0, # 后面可以考虑加一下，对误差比例进行缩放\n",
    "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
    "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "       'iou_t': 0.20,  # iou training threshold\n",
    "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
    "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
    "       'momentum': 0.937,  # SGD momentum\n",
    "       'weight_decay': 0.0005,  # optimizer weight decay\n",
    "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
    "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
    "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
    "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
    "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
    "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
    "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
    "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
    "nc = 7\n",
    "hyp['cls'] *= nc / 80  # update coco-tuned hyp['cls'] to current dataset\n",
    "# model.train()\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "cfg = 'cfg/yolov3-tiny-my.cfg'\n",
    "model = Darknet(cfg)\n",
    "\n",
    "model.nc = nc  # attach number of classes to model\n",
    "model.hyp = hyp  # attach hyperparameters to model\n",
    "model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n",
    "\n",
    "\"\"\"\n",
    "pytorch转onnx\n",
    "\"\"\"\n",
    "model.load_state_dict(torch.load('weights/best.pt'))\n",
    "# # 输入placeholder\n",
    "# dummy_input = torch.randint(0, 10000, (1, 20))\n",
    "# dummy_output = model_pytorch(dummy_input)\n",
    "# print(dummy_output.shape)\n",
    "\n",
    "# # Export to ONNX format\n",
    "# torch.onnx.export(model_pytorch, \n",
    "#                   dummy_input, \n",
    "#                   'model.onnx', \n",
    "#                   input_names=['inputs'], \n",
    "#                   output_names=['outputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHSPjjumLe2y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6dGh8cuFVEP"
   },
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfQAep_gFVEP"
   },
   "outputs": [],
   "source": [
    " [( tensor([0, 0, 0], device='cuda:0'), tensor([0, 0, 1]), tensor([2, 4, 2], device='cuda:0'), tensor([ 2, 10,  2], device='cuda:0')),\n",
    " # 如果这一层将三个锚盒与图片上的两个包围盒对比六次，然后发现有三个符合，\n",
    " # anchor是na*nt，锚盒数乘于目标数，然后那些筛选下来的锚盒，这是返回是哪个anchor，anchors返回的是对应的锚盒的大小\n",
    " # 然后就是对应包围盒的横坐标，纵坐标，这是根据该层网格大小确定的[是先纵坐标，再横坐标]\n",
    "  (tensor([0, 0, 0, 0, 0, 0], device='cuda:0'), tensor([0, 0, 1, 1, 2, 2]), tensor([5, 9, 5, 9, 5, 9], device='cuda:0'), tensor([ 5, 20,  5, 20,  5, 20], device='cuda:0')),\n",
    "  (tensor([], device='cuda:0', dtype=torch.int64), tensor([], dtype=torch.int64), tensor([], device='cuda:0', dtype=torch.int64), tensor([], device='cuda:0', dtype=torch.int64))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gJqXzf-FVEP"
   },
   "outputs": [],
   "source": [
    "out_targets = build_targets(output, tags, model)\n",
    "print(len(out_targets))\n",
    "print(out_targets[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vTCS0UVFVEP",
    "outputId": "f3046cc7-e704-410a-e618-798bc5ec26e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ332vuLFVEQ",
    "outputId": "295afacc-78a9-456a-c8d0-1f63eb143055"
   },
   "outputs": [],
   "source": [
    "# print(output[0].shape)\n",
    "\n",
    "gain = torch.ones(6, device=device)\n",
    "print(gain)\n",
    "gain[2:] = torch.tensor([1,3,13,13,12])[[3, 2, 3, 2]]\n",
    "print(gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMsRZTS6FVEQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "at = torch.arange(3)\n",
    "print(at)\n",
    "at = at.view(3, 1) # 变成3行一列\n",
    "print(at)\n",
    "at = at.repeat(1, 2) # 列重复\n",
    "print(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WEbPAjkFVEQ"
   },
   "outputs": [],
   "source": [
    "z = torch.zeros_like(at)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz1h4zFlFVEQ"
   },
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(loss_items)# 误差的量级应该尽量控制接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doeAlWBxFVER"
   },
   "outputs": [],
   "source": [
    "# 因为预测了很多个，需要与这些都进行误差计算，\n",
    "# 注意一下类别误差计算的维度怎么取，是否需要修改\n",
    "# 然后维度设置成和置信度一样就好了\n",
    "# 误差计算用了BCE逻辑回归，要看看，我看了似乎是二进制交叉熵？他说target只能是0和1？？\n",
    "# 不知道置信度为什么会用逻辑回归？好奇怪，这不应该是用在分类问题吗？\n",
    "# 我们还是用均方误差好一点\n",
    "print(output[0].shape)\n",
    "print(output[1].shape)\n",
    "print(output[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGU4LBJEFVER"
   },
   "outputs": [],
   "source": [
    "# loss的输入弄懂了，接下来看看他内部怎么处理\n",
    "# utils主要是负责计算loss\n",
    "# 接下来把思路好好整理一下，然后继续实验填写结果\n",
    "# 还有为什么把target分成3和6\n",
    "# 还有就是模型预测的输出不是13*13*3个包围盒\n",
    "# 问题应该出现在built target\n",
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "loss, loss_items = utils.utils.compute_loss(output, tag, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0Af2DOHFVER"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "gain = torch.ones(10, device=device)\n",
    "gain[2:6] = torch.tensor([1,3,13,13,12])[[3, 2, 3, 2]]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "tags = torch.tensor([[ 0.00000,  2.00000,  0.19658,  0.20487,  0.26816,  0.15605,0.1,0.2,0.3,0.4],[ 0.00000,  1.00000,  0.78653,  0.36487,  0.14542,  0.15631,0.1,0.2,0.3,0.4]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WURc90fJFVER",
    "outputId": "22a5e772-10e3-4cf9-9326-6bb0d92c8b96"
   },
   "outputs": [],
   "source": [
    "t = tags*gain # 因为坐标归一化了，所以乘于网格大小\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cDpmGhXFVER",
    "outputId": "b22f5889-3fb4-4fce-bfdd-dc276f929915"
   },
   "outputs": [],
   "source": [
    "gxy = t[:, 2:4]  # grid xy\n",
    "gwh = t[:, 4:6]  # grid wh\n",
    "garrow = t[:,6:10]\n",
    "print(gxy,gwh,garrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGEbYyeqFVES",
    "outputId": "f3b19842-566a-42b8-b100-052b8ffdfc69"
   },
   "outputs": [],
   "source": [
    "garrow[:,:2]*gwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2Rxa-BYFVES"
   },
   "outputs": [],
   "source": [
    "garrow[:,:2] = garrow[:,:2]*gwh+gxy-(gwh/2)\n",
    "garrow[:,2:4] = garrow[:,2:4]*gwh+gxy-(gwh/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9RdBCvPFVES",
    "outputId": "498ced24-0d19-491e-918f-08cc07ea0e49"
   },
   "outputs": [],
   "source": [
    "gwh/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoxpgmXCFVES",
    "outputId": "9b786d5f-246c-40a8-e28a-9f2696bed8d0"
   },
   "outputs": [],
   "source": [
    "# x1\n",
    "x1 = torch.tensor([[11,21,31],[21,31,41]],dtype=torch.int)\n",
    "x1.shape # torch.Size([2, 3])\n",
    "# x2\n",
    "x2 = torch.tensor([[12,22,32],[22,32,42]],dtype=torch.int)\n",
    "x2.shape  # torch.Size([2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f3-9rJGFVES",
    "outputId": "5f36201e-1d76-44fb-f82a-91e7fb7ae952"
   },
   "outputs": [],
   "source": [
    "inputs = (x1, x2)\n",
    "torch.cat(inputs, dim=1).shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "yolo_arow_new.ipynb",
   "provenance": [
    {
     "file_id": "1lWZR5JtWpV4W4yyqWsiK4TpqY9ZkD7Wm",
     "timestamp": 1621079503538
    },
    {
     "file_id": "1u2DuoH0aSM_qfdyluRK04NZ1Daa7FwvM",
     "timestamp": 1605694441066
    },
    {
     "file_id": "14Mhc8Qe1Am9ia2__UjFu9boIObnBGert",
     "timestamp": 1605587969420
    },
    {
     "file_id": "19nPB4ACou8UMyR5B8UHKGt66d8Clr3dL",
     "timestamp": 1604980233386
    }
   ]
  },
  "interpreter": {
   "hash": "2f3870ddede1b91ac1ef4abb86ebb1ca33ed1cea5f60d1e4a16ca28c07cd33e8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
